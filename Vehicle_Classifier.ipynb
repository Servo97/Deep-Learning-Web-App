{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JCM_PuSXlyDo",
    "outputId": "6ea0c669-e136-4fc4-9498-19942cacf39f"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "t7QYjidkmyWq",
    "outputId": "b454e1e5-f709-4c6b-f21e-bbd37dcaabeb"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,Nadam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vggnet import SmallerVGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#construct argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-d\",\"--data\",required = True,\n",
    "#                 help = \"path to input dataset\")\n",
    "# ap.add_argument(\"-m\",\"--model\",required = True,\n",
    "#                  help = \"path to model\")\n",
    "# ap.add_argument(\"-l\",\"--labelbin\",required=True,\n",
    "#                 help = \"path to output label binarizer\")\n",
    "# ap.add_argument(\"-p\",\"--plot\",type=str,default=\"plot.png\",\n",
    "#                 help=\"path to output accuracy vs loss plot\")\n",
    "# args = vars(ap.parse_args())\n",
    "#initialize epochs,learning rate,batch size and img dims\n",
    "epochs = 100\n",
    "lr = 0.0002\n",
    "bs = 64\n",
    "IMAGE_DIMS = (128,128,3)\n",
    "#initialize data and labels\n",
    "data = []\n",
    "labels = []\n",
    "print(\"[INFO] loading images ...\")\n",
    "imagePaths = sorted(list(paths.list_images('data')))\n",
    "random.seed(31)\n",
    "random.shuffle(imagePaths)\n",
    "f = 1\n",
    "#loop over input images\n",
    "for imagePath in imagePaths:\n",
    "    #load the image,preprocess it, and store it in data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    if image is not None:\n",
    "        image = cv2.resize(image,(IMAGE_DIMS[1],IMAGE_DIMS[0]))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        #extract class label; from the image path and update labels list\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        labels.append(label)\n",
    "        f+=1\n",
    "    \n",
    "print(f)\n",
    "#scale pixel intensities from 0-255 to 0-1\n",
    "data = np.array(data,dtype=\"float\")/255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(data.nbytes/(1024*1000.0)))\n",
    "#binarize labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(labels)\n",
    "#partition the data into training and testing splits using 80%\n",
    "#of the data for trainning and the remaining 20% for testing\n",
    "(trainX,testX,trainY,testY) = train_test_split(data,labels,\n",
    "    test_size=0.08,random_state = 31)\n",
    "\"\"\"Data Augmentation is IMP cos low data\"\"\"\n",
    "#construct image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range = 25,width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,shear_range=0.2,zoom_range=0.2,\n",
    "                         horizontal_flip=True,fill_mode=\"nearest\")\n",
    "#initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1],height=IMAGE_DIMS[0],\n",
    "                            depth=IMAGE_DIMS[2],classes=len(lb.classes_))\n",
    "opt = Nadam(lr=lr)\n",
    "#categorical crossentropy as multi-class output\n",
    "#for 2 classes outputs, use binary crossentropy\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX,trainY,batch_size=bs),\n",
    "                        validation_data=(testX,testY),\n",
    "                        steps_per_epoch=len(trainX)//bs,\n",
    "                        epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "0xfvWOejm7eG",
    "outputId": "b453f673-f9d5-41d4-f2d3-23ff5e40c6cf"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('vehicle0.model')\n",
    "#save label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f=open('lb.pickle',\"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "jlWwvzhL41Su",
    "outputId": "59a84ef1-4088-49e0-f418-4aa867f796b0"
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "n = epochs\n",
    "plt.plot(np.arange(0,n),H.history[\"loss\"],label=\"train_loss\")\n",
    "plt.plot(np.arange(0,n),H.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.plot(np.arange(0,n),H.history[\"acc\"],label = \"trian_acc\")\n",
    "plt.plot(np.arange(0,n),H.history[\"val_acc\"],label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "colab_type": "code",
    "id": "rWZ9U9TzzHZB",
    "outputId": "a97aef6b-cf93-45ef-f016-401825d44d03"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec  9 22:35:46 2018\n",
    "\n",
    "@author: servo97\n",
    "\"\"\"\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "'''ap.add_argument(\"-m\",\"--model\", required = True,\n",
    "                help=\"path to trained model\")\n",
    "ap.add_argument(\"-l\",\"--labelbin\",required = True,\n",
    "                help=\"path to label binarizer\")\n",
    "ap.add_argument(\"-i\",\"--image\",required=True,\n",
    "                help=\"path to input image\")\n",
    "args=vars(ap.parse_args())\n",
    "'''\n",
    "#load the model\n",
    "model = load_model(\"vehicle0.model\")\n",
    "lb= pickle.loads(open(\"lb.pickle\",\"rb\").read())\n",
    "\n",
    "image1 = cv2.imread(\"examples/10061.jpg\")\n",
    "op1 = image1.copy()\n",
    "image2 = cv2.imread(\"examples/80048.jpg\")\n",
    "op2 = image2.copy()\n",
    "image3 = cv2.imread(\"examples/th - 2019-03-31T221516.576.jpg\")\n",
    "op3 = image3.copy()\n",
    "\n",
    "image3 = cv2.resize(image3,(128,128))\n",
    "image3 = image3.astype(\"float\")/255.0\n",
    "image3 = img_to_array(image3)\n",
    "image3 = np.expand_dims(image3,axis=0)\n",
    "\n",
    "image1 = cv2.resize(image1,(128,128))\n",
    "image1 = image1.astype(\"float\")/255.0\n",
    "image1 = img_to_array(image1)\n",
    "image1 = np.expand_dims(image1,axis=0)\n",
    "\n",
    "image2 = cv2.resize(image2,(128,128))\n",
    "image2 = image2.astype(\"float\")/255.0\n",
    "image2 = img_to_array(image2)\n",
    "image2 = np.expand_dims(image2,axis=0)\n",
    "\n",
    "print(\"Classifying images...\")\n",
    "prob1 = model.predict(image1)[0]\n",
    "idx1 = np.argmax(prob1)\n",
    "label1 = lb.classes_[idx1]\n",
    "\n",
    "prob2 = model.predict(image2)[0]\n",
    "idx2 = np.argmax(prob2)\n",
    "label2 = lb.classes_[idx2]\n",
    "\n",
    "prob3 = model.predict(image3)[0]\n",
    "idx3 = np.argmax(prob3)\n",
    "label3 = lb.classes_[idx3]\n",
    "\n",
    "# we'll mark our prediction as \"correct\" of the input image filename\n",
    "# contains the predicted label text (obviously this makes the\n",
    "# assumption that you have named your testing image files this way)\n",
    "'''filename = args[\"image\"][args[\"image\"].rfind(os.path.sep) + 1:]\n",
    "correct = \"correct\" if filename.rfind(label)!=-1 else \"correct\"'''\n",
    "\n",
    "#build label and draw it on image\n",
    "label1 = \"{}: {:.2f}%\".format(label1,prob1[idx1]*100)\n",
    "op1 = imutils.resize(op1,width=400)\n",
    "cv2.putText(op1,label1,(10,25),cv2.FONT_HERSHEY_SIMPLEX,0.7,(200,0,0),2)\n",
    "print(label1)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = op1\n",
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_RGB2BGR))\n",
    "plt.show()\n",
    "\n",
    "label2 = \"{}: {:.2f}%\".format(label2,prob2[idx2]*100)\n",
    "op2 = imutils.resize(op2,width=400)\n",
    "cv2.putText(op2,label2,(10,25),cv2.FONT_HERSHEY_SIMPLEX,0.7,(200,0,0),2)\n",
    "print(label2)\n",
    "\n",
    "img2 = op2\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_RGB2BGR))\n",
    "plt.show()\n",
    "\n",
    "label3 = \"{}: {:.2f}%\".format(label3,prob3[idx3]*100)\n",
    "op3 = imutils.resize(op3,width=400)\n",
    "cv2.putText(op3,label3,(10,25),cv2.FONT_HERSHEY_SIMPLEX,0.7,(200,0,0),2)\n",
    "print(label3)\n",
    "\n",
    "img3 = op3\n",
    "plt.imshow(cv2.cvtColor(img3, cv2.COLOR_RGB2BGR))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojX8FiUVzXp1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Vehicle Classifier 6172.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
